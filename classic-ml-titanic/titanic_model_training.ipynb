{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üö¢ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º –≤—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–æ—Å–ª–µ –∫—Ä—É—à–µ–Ω–∏—è –¢–∏—Ç–∞–Ω–∏–∫–∞\n",
        "\n",
        "## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç\n",
        "\n",
        "### –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞:\n",
        "\n",
        "\n",
        "–ó–∞–ø—É—Å—Ç–∏—Ç–µ **–≤—Å–µ** —è—á–µ–π–∫–∏ —Å –∫–æ–¥–æ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑\n",
        "\n",
        "\n",
        "–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞:\n",
        "1. –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–¥ —è—á–µ–π–∫–æ–π\n",
        "3. –ó–∞–ø–∏—à–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ç–∞–±–ª–∏—Ü—É\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ –¶–µ–ª—å —Å–µ–º–∏–Ω–∞—Ä–∞\n",
        "\n",
        "**–î–æ—Å—Ç–∏—á—å Accuracy > 0.80 –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ**\n",
        "\n",
        "–ù–∞—á–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—Ç–æ–ª—å–∫–æ Pclass, Sex, Age):\n",
        "- Accuracy: ~0.77\n",
        "- Precision: ~0.73\n",
        "- Recall: ~0.62\n",
        "\n",
        "---\n",
        "\n",
        "## üìù –ö–∞–∫ –∏–∑–º–µ–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
        "\n",
        "### 1. –ò–∑–º–µ–Ω–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ (–®–ê–ì 1):\n",
        "\n",
        "–ù–∏–∂–µ, –≤ —è—á–µ–π–∫–µ —Å –∫–æ–¥–æ–º, –Ω–∞–π–¥–∏—Ç–µ —Å—Ç—Ä–æ–∫–∏:\n",
        "\n",
        "```python\n",
        "# ‚ö†Ô∏è –ü—Ä–∏–º–µ—Ä! –Ø—á–µ–π–∫–∞ —Å –∫–æ–¥–æ–º –Ω–∏–∂–µ\n",
        "features_to_use = [\n",
        "    'Pclass',\n",
        "    'Sex',\n",
        "    'Age',\n",
        "    # 'SibSp',     # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å\n",
        "    # 'Parch',     # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å\n",
        "    # 'Fare',      # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å\n",
        "    # 'Embarked',  # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å\n",
        "]\n",
        "```\n",
        "\n",
        "**–ß—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫:** —É–¥–∞–ª–∏—Ç–µ `#` –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏\n",
        "\n",
        "```python\n",
        "features_to_use = [\n",
        "    'Pclass',\n",
        "    'Sex',\n",
        "    'Age',\n",
        "    'Fare',      # –¢–µ–ø–µ—Ä—å –∞–∫—Ç–∏–≤–µ–Ω!\n",
        "]\n",
        "```\n",
        "\n",
        "### 2. –ò–∑–º–µ–Ω–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–®–ê–ì 2):\n",
        "\n",
        "–ù–∏–∂–µ, –≤ —è—á–µ–π–∫–µ —Å –∫–æ–¥–æ–º –Ω–∞–π–¥–∏—Ç–µ —Å—Ç—Ä–æ–∫–∏:\n",
        "\n",
        "```python\n",
        "# ‚ö†Ô∏è –ü—Ä–∏–º–µ—Ä! –Ø—á–µ–π–∫–∞ —Å –∫–æ–¥–æ–º –Ω–∏–∂–µ\n",
        "n_estimators = 100       # –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: 50, 100, 200, 500\n",
        "max_depth = 5            # –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: 3, 5, 10, 20, None\n",
        "min_samples_split = 10   # –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: 2, 5, 10, 20\n",
        "min_samples_leaf = 5     # –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: 1, 2, 5, 10\n",
        "```\n",
        "\n",
        "**–ü—Ä–æ—Å—Ç–æ –∏–∑–º–µ–Ω–∏—Ç–µ —á–∏—Å–ª–∞:**\n",
        "\n",
        "```python\n",
        "n_estimators = 200       # –£–≤–µ–ª–∏—á–∏–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤\n",
        "max_depth = 10           # –£–≤–µ–ª–∏—á–∏–ª–∏ –≥–ª—É–±–∏–Ω—É\n",
        "```\n",
        "\n",
        "### 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫–∏ —Å–Ω–æ–≤–∞:\n",
        "\n",
        "---\n",
        "\n",
        "## üìä –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "\n",
        "### Confusion Matrix (–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫):\n",
        "\n",
        "```\n",
        "                 –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ\n",
        "              –ù–µ –≤—ã–∂–∏–ª | –í—ã–∂–∏–ª\n",
        "            -----------|--------\n",
        "–†–µ–∞–ª—å–Ω–æ     |         |\n",
        "–ù–µ –≤—ã–∂–∏–ª    |   TN    |   FP    ‚Üê –õ–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è\n",
        "            |---------|--------|\n",
        "–í—ã–∂–∏–ª       |   FN    |   TP    ‚Üê –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "              ‚Üë\n",
        "        –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ\n",
        "```\n",
        "\n",
        "- **TN (True Negative)**: –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ \"–Ω–µ –≤—ã–∂–∏–ª\"\n",
        "- **TP (True Positive)**: –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ \"–≤—ã–∂–∏–ª\"\n",
        "- **FP (False Positive)**: –æ—à–∏–±–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ \"–≤—ã–∂–∏–ª\" (–ª–æ–∂–Ω–∞—è —Ç—Ä–µ–≤–æ–≥–∞)\n",
        "- **FN (False Negative)**: –æ—à–∏–±–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ \"–Ω–µ –≤—ã–∂–∏–ª\" (–ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏)\n",
        "\n",
        "### –ú–µ—Ç—Ä–∏–∫–∏:\n",
        "\n",
        "| –ú–µ—Ç—Ä–∏–∫–∞ | –§–æ—Ä–º—É–ª–∞ | –ß—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç |\n",
        "|---------|---------|----------------|\n",
        "| **Accuracy** | (TP + TN) / –í—Å–µ–≥–æ | –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å |\n",
        "| **Precision** | TP / (TP + FP) | –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π |\n",
        "| **Recall** | TP / (TP + FN) | –ü–æ–ª–Ω–æ—Ç–∞ (–Ω–∞—Ö–æ–¥–∏–º –ª–∏ –≤—Å–µ—Ö –≤—ã–∂–∏–≤—à–∏—Ö) |\n",
        "\n",
        "---\n",
        "\n",
        "## üí° –ü–æ–¥—Å–∫–∞–∑–∫–∏\n",
        "\n",
        "### –ï—Å–ª–∏ Accuracy < 0.70:\n",
        "- ‚úÖ –î–æ–±–∞–≤—å—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ `Sex` –∏ `Pclass` (—Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ!)\n",
        "- ‚úÖ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ —Å–ª–∏—à–∫–æ–º –æ–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å–Ω—ã–µ\n",
        "\n",
        "### –ï—Å–ª–∏ Accuracy 0.70-0.78:\n",
        "- ‚úÖ –î–æ–±–∞–≤—å—Ç–µ `Fare` –∏ `Age`\n",
        "- ‚úÖ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–≤–µ–ª–∏—á–∏—Ç—å `n_estimators` –¥–æ 200\n",
        "- ‚úÖ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ `max_depth=10`\n",
        "\n",
        "### –ï—Å–ª–∏ Accuracy > 0.78:\n",
        "- üéâ –û—Ç–ª–∏—á–Ω–æ! –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–ª—É—á—à–∏—Ç—å Recall\n",
        "- ‚úÖ –ü–æ—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å min_samples_split –∏ min_samples_leaf\n",
        "- ‚úÖ –î–æ–±–∞–≤—å—Ç–µ –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "\n",
        "### –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è:\n",
        "- Train Accuracy –Ω–∞–º–Ω–æ–≥–æ –≤—ã—à–µ Test Accuracy (—Ä–∞–∑–Ω–∏—Ü–∞ > 0.15)\n",
        "- **–†–µ—à–µ–Ω–∏–µ:** —É–º–µ–Ω—å—à–∏—Ç–µ `max_depth`, —É–≤–µ–ª–∏—á—å—Ç–µ `min_samples_split`\n",
        "\n",
        "### –ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—è:\n",
        "- –ò Train, –∏ Test Accuracy –Ω–∏–∑–∫–∏–µ (< 0.75)\n",
        "- **–†–µ—à–µ–Ω–∏–µ:** –¥–æ–±–∞–≤—å—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, —É–≤–µ–ª–∏—á—å—Ç–µ `max_depth`\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ –ó–∞–¥–∞–Ω–∏—è —Å–µ–º–∏–Ω–∞—Ä–∞\n",
        "\n",
        "### –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å ‚≠ê:\n",
        "1. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–∫—Ä–∏–ø—Ç —Å –±–∞–∑–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
        "2. –í—ã—á–∏—Å–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤—Ä—É—á–Ω—É—é\n",
        "3. –î–æ–±–∞–≤–∏—Ç—å 2-3 –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞\n",
        "4. –°—Ä–∞–≤–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "\n",
        "### –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å ‚≠ê‚≠ê:\n",
        "1. –ü—Ä–æ–≤–µ—Å—Ç–∏ 5+ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤\n",
        "2. –î–æ—Å—Ç–∏—á—å Accuracy > 0.80\n",
        "3. –ù–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
        "4. –û–±—ä—è—Å–Ω–∏—Ç—å trade-off –º–µ–∂–¥—É Precision –∏ Recall\n",
        "\n",
        "### –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å ‚≠ê‚≠ê‚≠ê:\n",
        "1. –î–æ—Å—Ç–∏—á—å Accuracy > 0.82\n",
        "2. –ú–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É Train –∏ Test\n",
        "3. –û–±—ä—è—Å–Ω–∏—Ç—å –≤–ª–∏—è–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞\n",
        "4. –ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
        "\n",
        "---\n",
        "\n",
        "## üìà –ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "\n",
        "–ü–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —Å–æ–∑–¥–∞—ë—Ç—Å—è —Ñ–∞–π–ª `seminar_results.png` —Å–æ –≤—Å–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π:\n",
        "\n",
        "- üîµ **Confusion Matrix** - –º–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫\n",
        "- üìä **–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤** - –∫–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–ª–∏—è—é—Ç –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ\n",
        "- üìà **–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞** - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Accuracy, Precision, Recall\n",
        "- üìâ **–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤** - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö\n",
        "- üéØ **ROC Curve** - –æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞\n",
        "- üìù **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è** - –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∞—à–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ùì FAQ\n",
        "\n",
        "**Q: –ù—É–∂–Ω–æ –ª–∏ –∑–Ω–∞—Ç—å Python?**\n",
        "A: –ù–µ—Ç! –í–∞–º –Ω—É–∂–Ω–æ —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω—è—Ç—å —á–∏—Å–ª–∞ –∏ —É–¥–∞–ª—è—Ç—å —Å–∏–º–≤–æ–ª—ã `#`.\n",
        "\n",
        "**Q: –ö–∞–∫ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫—É?**\n",
        "A: –£–¥–∞–ª–∏—Ç–µ `#` –≤ –Ω–∞—á–∞–ª–µ. –ë—ã–ª–æ: `# 'Fare',` ‚Üí –°—Ç–∞–ª–æ: `'Fare',`\n",
        "\n",
        "**Q: –°–∫—Ä–∏–ø—Ç –≤—ã–¥–∞—ë—Ç –æ—à–∏–±–∫—É!**\n",
        "A: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\n",
        "1. –ù–µ –∑–∞–±—ã–ª–∏ –ª–∏ –∑–∞–ø—è—Ç—ã–µ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
        "2. –ù–µ —É–¥–∞–ª–∏–ª–∏ –ª–∏ —Å–ª—É—á–∞–π–Ω–æ –≤–∞–∂–Ω—É—é —Å—Ç—Ä–æ–∫—É –∫–æ–¥–∞\n",
        "\n",
        "**Q: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∂–¥—ã–π —Ä–∞–∑ —Ä–∞–∑–Ω—ã–µ?**\n",
        "A: –ù–µ–±–æ–ª—å—à–∏–µ —Ä–∞–∑–ª–∏—á–∏—è (¬±0.01) –Ω–æ—Ä–º–∞–ª—å–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `random_state=42` –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.\n",
        "\n",
        "**Q: –ú–æ–∂–Ω–æ –ª–∏ –¥–æ—Å—Ç–∏—á—å 100% Accuracy?**\n",
        "A: –ù–µ—Ç. 80-83% - —ç—Ç–æ –æ—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö!\n",
        "\n",
        "**Q: –°–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–Ω–∏–º–∞–µ—Ç –∑–∞–ø—É—Å–∫?**\n",
        "A: 5-10 —Å–µ–∫—É–Ω–¥ –¥–ª—è –±–∞–∑–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, –¥–æ 30 —Å–µ–∫—É–Ω–¥ —Å max_depth=None –∏ n_estimators=500.\n",
        "\n",
        "---\n",
        "\n",
        "## üìö –ß—Ç–æ –¥–∞–ª—å—à–µ?\n",
        "\n",
        "–ü–æ—Å–ª–µ —Å–µ–º–∏–Ω–∞—Ä–∞ –≤—ã –º–æ–∂–µ—Ç–µ:\n",
        "\n",
        "1. **–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã:**\n",
        "   - Logistic Regression (–ø—Ä–æ—â–µ, –±—ã—Å—Ç—Ä–µ–µ)\n",
        "   - Gradient Boosting (—á–∞—Å—Ç–æ –ª—É—á—à–µ)\n",
        "\n",
        "2. **–£–ª—É—á—à–∏—Ç—å –¥–∞–Ω–Ω—ã–µ:**\n",
        "   - Feature engineering (—Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)\n",
        "   - –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤\n",
        "   - –ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤\n",
        "\n",
        "3. **–£–ª—É—á—à–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é:**\n",
        "   - Cross-validation\n",
        "   - Stratified K-Fold\n",
        "   - –û—Ç–¥–µ–ª—å–Ω—ã–π validation set\n",
        "\n",
        "---\n",
        "\n",
        "**–£–¥–∞—á–∏ –Ω–∞ —Å–µ–º–∏–Ω–∞—Ä–µ! üöÄ**\n"
      ],
      "metadata": {
        "id": "ZZO8MHOEdfdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "–°–ï–ú–ò–ù–ê–†: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç–∏ –Ω–∞ –¢–∏—Ç–∞–Ω–∏–∫–µ\n",
        "\n",
        "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:\n",
        "1. –ò–∑–º–µ–Ω–∏—Ç–µ —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —Å–µ–∫—Ü–∏–∏ \"–®–ê–ì 1\"\n",
        "2. –ò–∑–º–µ–Ω–∏—Ç–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –≤ —Å–µ–∫—Ü–∏–∏ \"–®–ê–ì 2\"\n",
        "3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç: python titanic_seminar.py\n",
        "4. –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ confusion matrix (–º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫)\n",
        "5. –í—ã—á–∏—Å–ª–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –≤—Ä—É—á–Ω—É—é –≤ —Å–µ–∫—Ü–∏–∏ \"–®–ê–ì 3\"\n",
        "6. –°—Ä–∞–≤–Ω–∏—Ç–µ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"–°–ï–ú–ò–ù–ê–†: –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –í–´–ñ–ò–í–ê–ï–ú–û–°–¢–ò –ù–ê –¢–ò–¢–ê–ù–ò–ö–ï\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ============================================================================\n",
        "# –ó–ê–ì–†–£–ó–ö–ê –ò –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\")\n",
        "train_file = Path('train.csv')\n",
        "if train_file.exists():\n",
        "  df = pd.read_csv(train_file)\n",
        "else:\n",
        "  df = pd.read_csv('../train.csv')\n",
        "print(f\"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {df.shape[0]} –∑–∞–ø–∏—Å–µ–π –æ –ø–∞—Å—Å–∞–∂–∏—Ä–∞—Ö\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# –®–ê–ì 1: –í–´–ë–û–† –ü–†–ò–ó–ù–ê–ö–û–í –î–õ–Ø –ú–û–î–ï–õ–ò\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"–®–ê–ì 1: –í–´–ë–û–† –ü–†–ò–ó–ù–ê–ö–û–í\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\")\n",
        "print(\"  - Pclass:   –ö–ª–∞—Å—Å –±–∏–ª–µ—Ç–∞ (1, 2, 3)\")\n",
        "print(\"  - Sex:      –ü–æ–ª (male/female)\")\n",
        "print(\"  - Age:      –í–æ–∑—Ä–∞—Å—Ç\")\n",
        "print(\"  - SibSp:    –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—Ä–∞—Ç—å–µ–≤/—Å–µ—Å—Ç—ë—Ä/—Å—É–ø—Ä—É–≥–æ–≤ –Ω–∞ –±–æ—Ä—Ç—É\")\n",
        "print(\"  - Parch:    –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–æ–¥–∏—Ç–µ–ª–µ–π/–¥–µ—Ç–µ–π –Ω–∞ –±–æ—Ä—Ç—É\")\n",
        "print(\"  - Fare:     –°—Ç–æ–∏–º–æ—Å—Ç—å –±–∏–ª–µ—Ç–∞\")\n",
        "print(\"  - Embarked: –ü–æ—Ä—Ç –ø–æ—Å–∞–¥–∫–∏ (S, C, Q)\")\n",
        "\n",
        "# ‚ö†Ô∏è –ò–ó–ú–ï–ù–ò–¢–ï –≠–¢–û–¢ –°–ü–ò–°–û–ö!\n",
        "# –î–æ–±–∞–≤—å—Ç–µ –∏–ª–∏ —É–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, —á—Ç–æ–±—ã —É–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å\n",
        "features_to_use = [\n",
        "    'Pclass',\n",
        "    'Sex',\n",
        "    'Age',\n",
        "    # 'SibSp',     # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å\n",
        "    # 'Parch',     # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å\n",
        "    # 'Fare',      # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å\n",
        "    # 'Embarked',  # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å\n",
        "]\n",
        "\n",
        "print(f\"\\n‚úì –í—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {features_to_use}\")\n",
        "\n",
        "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "X = df[features_to_use].copy()\n",
        "y = df['Survived']\n",
        "\n",
        "# –°–Ω–∞—á–∞–ª–∞ –∫–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –ø–æ—Ç–æ–º –∑–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –ø–µ—Ä–µ–¥ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º\n",
        "    X[col] = X[col].fillna(X[col].mode()[0])\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "\n",
        "# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
        "for col in numerical_columns:\n",
        "    X[col] = X[col].fillna(X[col].median())\n",
        "\n",
        "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train –∏ test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"‚úì –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_train)} –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤\")\n",
        "print(f\"‚úì –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞:  {len(X_test)} –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤\")"
      ],
      "metadata": {
        "id": "ARPL9k41jMat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xpf6FY31dH7I"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# –®–ê–ì 2: –ù–ê–°–¢–†–û–ô–ö–ê –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–û–í –ú–û–î–ï–õ–ò\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"–®–ê–ì 2: –ù–ê–°–¢–†–û–ô–ö–ê –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–û–í\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüìä –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã Random Forest:\")\n",
        "print(\"  - n_estimators:     –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ –≤ –ª–µ—Å—É\")\n",
        "print(\"  - max_depth:        –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞\")\n",
        "print(\"  - min_samples_split: –ú–∏–Ω–∏–º—É–º –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —É–∑–ª–∞\")\n",
        "print(\"  - min_samples_leaf: –ú–∏–Ω–∏–º—É–º –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –ª–∏—Å—Ç–µ\")\n",
        "\n",
        "# ‚ö†Ô∏è –ò–ó–ú–ï–ù–ò–¢–ï –≠–¢–ò –ü–ê–†–ê–ú–ï–¢–†–´!\n",
        "# –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, —á—Ç–æ–±—ã —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏\n",
        "n_estimators = 100       # –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: 50, 100, 200, 500\n",
        "max_depth = 5            # –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: 3, 5, 10, 20, None\n",
        "min_samples_split = 10   # –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: 2, 5, 10, 20\n",
        "min_samples_leaf = 5     # –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: 1, 2, 5, 10\n",
        "\n",
        "print(f\"\\n‚úì –í—ã–±—Ä–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
        "print(f\"  - n_estimators:      {n_estimators}\")\n",
        "print(f\"  - max_depth:         {max_depth}\")\n",
        "print(f\"  - min_samples_split: {min_samples_split}\")\n",
        "print(f\"  - min_samples_leaf:  {min_samples_leaf}\")\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "print(f\"\\nüîÑ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...\")\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=n_estimators,\n",
        "    max_depth=max_depth,\n",
        "    min_samples_split=min_samples_split,\n",
        "    min_samples_leaf=min_samples_leaf,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"‚úì –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!\")\n",
        "\n",
        "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "y_test_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# –†–ï–ó–£–õ–¨–¢–ê–¢–´: CONFUSION MATRIX (–ú–ê–¢–†–ò–¶–ê –û–®–ò–ë–û–ö)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"–†–ï–ó–£–õ–¨–¢–ê–¢–´: CONFUSION MATRIX\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫ –≤—Ä—É—á–Ω—É—é\n",
        "TP = 0  # True Positive:  –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ –≤—ã–∂–∏–ª (1) –∏ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –≤—ã–∂–∏–ª (1)\n",
        "TN = 0  # True Negative:  –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ –Ω–µ –≤—ã–∂–∏–ª (0) –∏ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –Ω–µ –≤—ã–∂–∏–ª (0)\n",
        "FP = 0  # False Positive: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ –≤—ã–∂–∏–ª (1), –Ω–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –Ω–µ –≤—ã–∂–∏–ª (0)\n",
        "FN = 0  # False Negative: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ –Ω–µ –≤—ã–∂–∏–ª (0), –Ω–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –≤—ã–∂–∏–ª (1)\n",
        "\n",
        "for true_val, pred_val in zip(y_test, y_test_pred):\n",
        "    if true_val == 1 and pred_val == 1:\n",
        "        TP += 1\n",
        "    elif true_val == 0 and pred_val == 0:\n",
        "        TN += 1\n",
        "    elif true_val == 0 and pred_val == 1:\n",
        "        FP += 1\n",
        "    elif true_val == 1 and pred_val == 0:\n",
        "        FN += 1\n",
        "\n",
        "print(\"\\nüìä Confusion Matrix:\")\n",
        "print(f\"\"\"\n",
        "                      –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ\n",
        "                   –ù–µ –≤—ã–∂–∏–ª | –í—ã–∂–∏–ª\n",
        "                   ---------|--------\n",
        "–†–µ–∞–ª—å–Ω–æ  –ù–µ –≤—ã–∂–∏–ª |   {TN:3d}   |  {FP:3d}\n",
        "         –í—ã–∂–∏–ª    |   {FN:3d}   |  {TP:3d}\n",
        "\"\"\")\n",
        "\n",
        "print(f\"–û–±–æ–∑–Ω–∞—á–µ–Ω–∏—è:\")\n",
        "print(f\"  TN (True Negative)  = {TN:3d}  - –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ '–Ω–µ –≤—ã–∂–∏–ª'\")\n",
        "print(f\"  TP (True Positive)  = {TP:3d}  - –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ '–≤—ã–∂–∏–ª'\")\n",
        "print(f\"  FP (False Positive) = {FP:3d}  - –æ—à–∏–±–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ '–≤—ã–∂–∏–ª'\")\n",
        "print(f\"  FN (False Negative) = {FN:3d}  - –æ—à–∏–±–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ '–Ω–µ –≤—ã–∂–∏–ª'\")\n",
        "print(f\"  –í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤      = {TN + TP + FP + FN}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# –®–ê–ì 3: –í–´–ß–ò–°–õ–ï–ù–ò–ï –ú–ï–¢–†–ò–ö (–ó–ê–ü–û–õ–ù–ò–¢–ï –°–ê–ú–ò!)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"–®–ê–ì 3: –í–´–ß–ò–°–õ–ï–ù–ò–ï –ú–ï–¢–†–ò–ö\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüìù –ó–ê–î–ê–ù–ò–ï: –í—ã—á–∏—Å–ª–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –≤—Ä—É—á–Ω—É—é, –∏—Å–ø–æ–ª—å–∑—É—è –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ Confusion Matrix\")\n",
        "print(\"   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è: TP={}, TN={}, FP={}, FN={}\".format(TP, TN, FP, FN))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚ö†Ô∏è –ó–ê–ü–û–õ–ù–ò–¢–ï –§–û–†–ú–£–õ–´!\n",
        "# –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –∏ –¥–æ–ø–∏—à–∏—Ç–µ —Ñ–æ—Ä–º—É–ª—ã –ø–æ—Å–ª–µ –∑–Ω–∞–∫–∞ =\n",
        "\n",
        "print(\"1Ô∏è‚É£  ACCURACY (–¢–æ—á–Ω–æ—Å—Ç—å) - –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\")\n",
        "print(\"   –§–æ—Ä–º—É–ª–∞: (TP + TN) / (TP + TN + FP + FN)\")\n",
        "# accuracy = ???  # –î–æ–ø–∏—à–∏—Ç–µ —Ñ–æ—Ä–º—É–ª—É\n",
        "print(f\"   –í–∞—à –æ—Ç–≤–µ—Ç: ________\")\n",
        "print()\n",
        "\n",
        "print(\"2Ô∏è‚É£  PRECISION (–ü—Ä–µ—Ü–∏–∑–∏–æ–Ω–Ω–æ—Å—Ç—å) - –∏–∑ —Ç–µ—Ö, –∫–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ –∫–∞–∫ '–≤—ã–∂–∏–ª',\")\n",
        "print(\"   —Å–∫–æ–ª—å–∫–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤—ã–∂–∏–ª–æ\")\n",
        "print(\"   –§–æ—Ä–º—É–ª–∞: TP / (TP + FP)\")\n",
        "# precision = ???  # –î–æ–ø–∏—à–∏—Ç–µ —Ñ–æ—Ä–º—É–ª—É\n",
        "print(f\"   –í–∞—à –æ—Ç–≤–µ—Ç: ________\")\n",
        "print()\n",
        "\n",
        "print(\"3Ô∏è‚É£  RECALL (–ü–æ–ª–Ω–æ—Ç–∞) - –∏–∑ —Ç–µ—Ö, –∫—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤—ã–∂–∏–ª,\")\n",
        "print(\"   —Å–∫–æ–ª—å–∫–æ –º—ã —Å–º–æ–≥–ª–∏ –Ω–∞–π—Ç–∏\")\n",
        "print(\"   –§–æ—Ä–º—É–ª–∞: TP / (TP + FN)\")\n",
        "# recall = ???  # –î–æ–ø–∏—à–∏—Ç–µ —Ñ–æ—Ä–º—É–ª—É\n",
        "print(f\"   –í–∞—à –æ—Ç–≤–µ—Ç: ________\")\n",
        "print()"
      ],
      "metadata": {
        "id": "H9X5nxJ7jZI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# –ü–†–ê–í–ò–õ–¨–ù–´–ï –û–¢–í–ï–¢–´ (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"–ü–†–ê–í–ò–õ–¨–ù–´–ï –û–¢–í–ï–¢–´ (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "accuracy_correct = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision_correct = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "recall_correct = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "print(f\"\\n‚úì Accuracy:    {accuracy_correct:.4f}  ({accuracy_correct*100:.2f}%)\")\n",
        "print(f\"‚úì Precision:   {precision_correct:.4f}  ({precision_correct*100:.2f}%)\")\n",
        "print(f\"‚úì Recall:      {recall_correct:.4f}  ({recall_correct*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nüìñ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:\")\n",
        "if accuracy_correct > 0.8:\n",
        "    print(f\"   ‚Ä¢ Accuracy {accuracy_correct:.2%} - –û–¢–õ–ò–ß–ù–û! –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ\")\n",
        "elif accuracy_correct > 0.7:\n",
        "    print(f\"   ‚Ä¢ Accuracy {accuracy_correct:.2%} - –•–û–†–û–®–û, –Ω–æ –µ—Å—Ç—å –∫—É–¥–∞ —Ä–∞—Å—Ç–∏\")\n",
        "else:\n",
        "    print(f\"   ‚Ä¢ Accuracy {accuracy_correct:.2%} - –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\")\n",
        "\n",
        "if precision_correct > 0.75:\n",
        "    print(f\"   ‚Ä¢ Precision {precision_correct:.2%} - –ú–∞–ª–æ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π\")\n",
        "else:\n",
        "    print(f\"   ‚Ä¢ Precision {precision_correct:.2%} - –ú–Ω–æ–≥–æ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π (FP)\")\n",
        "\n",
        "if recall_correct > 0.75:\n",
        "    print(f\"   ‚Ä¢ Recall {recall_correct:.2%} - –•–æ—Ä–æ—à–æ –Ω–∞—Ö–æ–¥–∏–º –≤—ã–∂–∏–≤—à–∏—Ö\")\n",
        "else:\n",
        "    print(f\"   ‚Ä¢ Recall {recall_correct:.2%} - –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–Ω–æ–≥–∏—Ö –≤—ã–∂–∏–≤—à–∏—Ö (FN)\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"–í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    '–ü—Ä–∏–∑–Ω–∞–∫': X.columns,\n",
        "    '–í–∞–∂–Ω–æ—Å—Ç—å': clf.feature_importances_\n",
        "}).sort_values('–í–∞–∂–Ω–æ—Å—Ç—å', ascending=False)\n",
        "\n",
        "print(\"\\nüìä –ö–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –≤–ª–∏—è—é—Ç –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:\\n\")\n",
        "for idx, row in feature_importance.iterrows():\n",
        "    bar_length = int(row['–í–∞–∂–Ω–æ—Å—Ç—å'] * 50)\n",
        "    bar = '‚ñà' * bar_length\n",
        "    print(f\"  {row['–ü—Ä–∏–∑–Ω–∞–∫']:12s} {'‚îÇ'} {bar} {row['–í–∞–∂–Ω–æ—Å—Ç—å']:.3f}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# –ü–û–°–¢–†–û–ï–ù–ò–ï –ì–†–ê–§–ò–ö–û–í\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"–ü–û–°–¢–†–û–ï–ù–ò–ï –ì–†–ê–§–ò–ö–û–í\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# –°–æ–∑–¥–∞—ë–º –±–æ–ª—å—à–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "\n",
        "# 1. Confusion Matrix –∫–∞–∫ heatmap\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "confusion = np.array([[TN, FP], [FN, TP]])\n",
        "im = ax1.imshow(confusion, cmap='Blues', alpha=0.8)\n",
        "ax1.set_xticks([0, 1])\n",
        "ax1.set_yticks([0, 1])\n",
        "ax1.set_xticklabels(['–ù–µ –≤—ã–∂–∏–ª', '–í—ã–∂–∏–ª'])\n",
        "ax1.set_yticklabels(['–ù–µ –≤—ã–∂–∏–ª', '–í—ã–∂–∏–ª'])\n",
        "ax1.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ', fontsize=11)\n",
        "ax1.set_ylabel('–†–µ–∞–ª—å–Ω–æ', fontsize=11)\n",
        "ax1.set_title('Confusion Matrix', fontsize=12, fontweight='bold')\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º —á–∏—Å–ª–∞ –≤ —è—á–µ–π–∫–∏\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        text = ax1.text(j, i, confusion[i, j],\n",
        "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=20)\n",
        "\n",
        "# 2. –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(feature_importance)))\n",
        "ax2.barh(feature_importance['–ü—Ä–∏–∑–Ω–∞–∫'], feature_importance['–í–∞–∂–Ω–æ—Å—Ç—å'], color=colors)\n",
        "ax2.set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å', fontsize=11)\n",
        "ax2.set_title('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=12, fontweight='bold')\n",
        "ax2.invert_yaxis()\n",
        "\n",
        "# 3. –ú–µ—Ç—Ä–∏–∫–∏\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "metrics = ['Accuracy', 'Precision', 'Recall']\n",
        "values = [accuracy_correct, precision_correct, recall_correct]\n",
        "colors_metrics = ['#2ecc71' if v > 0.75 else '#f39c12' if v > 0.6 else '#e74c3c' for v in values]\n",
        "bars = ax3.bar(metrics, values, color=colors_metrics, alpha=0.7, edgecolor='black')\n",
        "ax3.set_ylim([0, 1])\n",
        "ax3.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ', fontsize=11)\n",
        "ax3.set_title('–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞', fontsize=12, fontweight='bold')\n",
        "ax3.axhline(y=0.8, color='green', linestyle='--', alpha=0.3, label='–•–æ—Ä–æ—à–æ (>0.8)')\n",
        "ax3.axhline(y=0.6, color='orange', linestyle='--', alpha=0.3, label='–°—Ä–µ–¥–Ω–µ (>0.6)')\n",
        "ax3.legend(fontsize=8)\n",
        "for bar, val in zip(bars, values):\n",
        "    height = bar.get_height()\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "            f'{val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# 4. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "survived_counts = [TN + FP, TP + FN]\n",
        "predicted_counts = [TN + FN, TP + FP]\n",
        "x = np.arange(2)\n",
        "width = 0.35\n",
        "ax4.bar(x - width/2, survived_counts, width, label='–†–µ–∞–ª—å–Ω–æ–µ', alpha=0.8, color='#3498db')\n",
        "ax4.bar(x + width/2, predicted_counts, width, label='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ', alpha=0.8, color='#e74c3c')\n",
        "ax4.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', fontsize=11)\n",
        "ax4.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤', fontsize=12, fontweight='bold')\n",
        "ax4.set_xticks(x)\n",
        "ax4.set_xticklabels(['–ù–µ –≤—ã–∂–∏–ª (0)', '–í—ã–∂–∏–ª (1)'])\n",
        "ax4.legend()\n",
        "\n",
        "# 5. ROC Curve\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "y_test_proba = clf.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
        "auc = roc_auc_score(y_test, y_test_proba)\n",
        "ax5.plot(fpr, tpr, linewidth=2, label=f'AUC = {auc:.3f}', color='#e74c3c')\n",
        "ax5.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
        "ax5.set_xlabel('False Positive Rate', fontsize=11)\n",
        "ax5.set_ylabel('True Positive Rate', fontsize=11)\n",
        "ax5.set_title('ROC Curve', fontsize=12, fontweight='bold')\n",
        "ax5.legend()\n",
        "ax5.grid(alpha=0.3)\n",
        "\n",
        "# 6. –¢–µ–∫—Å—Ç–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "ax6.axis('off')\n",
        "info_text = f\"\"\"\n",
        "–ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê\n",
        "\n",
        "–ü—Ä–∏–∑–Ω–∞–∫–∏ ({len(features_to_use)}):\n",
        "  {', '.join(features_to_use)}\n",
        "\n",
        "–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
        "  ‚Ä¢ n_estimators: {n_estimators}\n",
        "  ‚Ä¢ max_depth: {max_depth}\n",
        "  ‚Ä¢ min_samples_split: {min_samples_split}\n",
        "  ‚Ä¢ min_samples_leaf: {min_samples_leaf}\n",
        "\n",
        "–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:\n",
        "  ‚Ä¢ Train: {len(X_train)} –ø—Ä–∏–º–µ—Ä–æ–≤\n",
        "  ‚Ä¢ Test:  {len(X_test)} –ø—Ä–∏–º–µ—Ä–æ–≤\n",
        "\n",
        "–†–ï–ó–£–õ–¨–¢–ê–¢–´\n",
        "\n",
        "Confusion Matrix:\n",
        "  TN={TN}  FP={FP}\n",
        "  FN={FN}  TP={TP}\n",
        "\n",
        "–ú–µ—Ç—Ä–∏–∫–∏:\n",
        "  Accuracy:    {accuracy_correct:.4f}\n",
        "  Precision:   {precision_correct:.4f}\n",
        "  Recall:      {recall_correct:.4f}\n",
        "\"\"\"\n",
        "ax6.text(0.05, 0.95, info_text, transform=ax6.transAxes,\n",
        "        fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
        "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
        "\n",
        "plt.suptitle('–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ - Titanic Survival Prediction',\n",
        "            fontsize=16, fontweight='bold', y=0.98)\n",
        "plt.tight_layout()\n",
        "plt.savefig('seminar_results.png', dpi=200, bbox_inches='tight')\n",
        "print(\"\\n‚úì –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ —Ñ–∞–π–ª: seminar_results.png\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"–°–ï–ú–ò–ù–ê–† –ó–ê–í–ï–†–®–Å–ù!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nüí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:\")\n",
        "print(\"  1. –í–µ—Ä–Ω–∏—Ç–µ—Å—å –∫ –®–ê–ì 1 –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\")\n",
        "print(\"  2. –ò–∑–º–µ–Ω–∏—Ç–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –®–ê–ì 2\")\n",
        "print(\"  3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç —Å–Ω–æ–≤–∞ –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\")\n",
        "print(\"  4. –¶–µ–ª—å: –¥–æ—Å—Ç–∏—á—å Accuracy > 0.80 –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ\")\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "wFLDvv_1jT1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèÜ –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "\n",
        "–ó–∞–ø–∏—à–∏—Ç–µ —Å–≤–æ–∏ –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ç–∞–±–ª–∏—Ü—É:\n",
        "\n",
        "| –ú–µ—Å—Ç–æ | Accuracy | –ü—Ä–∏–∑–Ω–∞–∫–∏ | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã |\n",
        "|-------|----------|----------|-----------|\n",
        "| 1     |          |          |           |\n",
        "| 2     |          |          |           |\n",
        "| 3     |          |          |           |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "snHr3WuuhItS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r4cb5nj4f2Ia"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}